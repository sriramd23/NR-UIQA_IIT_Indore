{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnMM5mqolQx8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import scipy.stats\n",
        "from scipy.optimize import curve_fit\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "NUM_ITERATIONS = 500\n",
        "N_JOBS = -1\n",
        "\n",
        "def get_dataset_info(prompt_text):\n",
        "    print(f\"\\n--- {prompt_text} ---\")\n",
        "    print(\"1. UID (Expects 'mos_UID.xlsx')\")\n",
        "    print(\"2. SAUD (Expects 'SAUD_MOS.xlsx')\")\n",
        "\n",
        "    choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "    if choice == '1':\n",
        "        mos_file = \"mos_UID.xlsx\"\n",
        "        name = \"UID\"\n",
        "    elif choice == '2':\n",
        "        mos_file = \"SAUD_MOS.xlsx\"\n",
        "        name = \"SAUD\"\n",
        "    else:\n",
        "        print(\"Invalid selection. Defaulting to UID.\")\n",
        "        mos_file = \"mos_UID.xlsx\"\n",
        "        name = \"UID\"\n",
        "\n",
        "    if not os.path.exists(mos_file):\n",
        "        print(f\"[ERROR] '{mos_file}' not found. Please upload it.\")\n",
        "        return None, None, None\n",
        "\n",
        "    zip_name = input(f\"Enter the features ZIP file for {name}: \").strip()\n",
        "\n",
        "    if not os.path.exists(zip_name):\n",
        "        print(f\"[ERROR] '{zip_name}' not found.\")\n",
        "        return None, None, None\n",
        "\n",
        "    return name, mos_file, zip_name\n",
        "\n",
        "def unzip_features(zip_name, extract_to):\n",
        "    # Clean up if exists\n",
        "    if os.path.exists(extract_to):\n",
        "        import shutil\n",
        "        shutil.rmtree(extract_to)\n",
        "    os.makedirs(extract_to)\n",
        "\n",
        "    print(f\"Unzipping {zip_name} into {extract_to}...\")\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "def load_features_from_folder(feature_folder, df_mos, name_col, mos_col):\n",
        "    \"\"\"\n",
        "    Loads features from a specific folder (e.g., 'S1_FA') and matches with MOS.\n",
        "    \"\"\"\n",
        "    # 1. Map Files\n",
        "    file_map = {}\n",
        "    for root, _, files in os.walk(feature_folder):\n",
        "        for f in files:\n",
        "            if f.endswith('.mat'):\n",
        "                # Store lower case keys for robust matching\n",
        "                file_map[f.lower()] = os.path.join(root, f)\n",
        "                file_map[os.path.splitext(f)[0].lower()] = os.path.join(root, f)\n",
        "\n",
        "    features = []\n",
        "    scores = []\n",
        "\n",
        "    # 2. Align\n",
        "    for _, row in df_mos.iterrows():\n",
        "        fname = str(row[name_col]).strip()\n",
        "        key = os.path.basename(fname).lower()\n",
        "        key_no_ext = os.path.splitext(key)[0]\n",
        "\n",
        "        path = file_map.get(key) or file_map.get(key_no_ext)\n",
        "\n",
        "        if path:\n",
        "            try:\n",
        "                mat = scipy.io.loadmat(path)\n",
        "                k = [k for k in mat.keys() if not k.startswith('__')][0]\n",
        "                feat_vec = np.array(mat[k]).flatten()\n",
        "                features.append(feat_vec)\n",
        "                scores.append(row[mos_col])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return np.array(features), np.array(scores)\n",
        "\n",
        "def logistic_func(X, b1, b2, b3, b4):\n",
        "    logisticPart = 1 + np.exp(-(X - b3) / np.abs(b4))\n",
        "    yhat = b2 + (b1 - b2) / logisticPart\n",
        "    return yhat\n",
        "\n",
        "def compute_metrics(y_pred, y):\n",
        "    try:\n",
        "        beta_init = [np.max(y), np.min(y), np.mean(y_pred), 0.5]\n",
        "        popt, _ = curve_fit(logistic_func, y_pred, y, p0=beta_init, maxfev=int(1e8))\n",
        "        y_pred_logistic = logistic_func(y_pred, *popt)\n",
        "    except:\n",
        "        y_pred_logistic = y_pred\n",
        "\n",
        "    SRCC = scipy.stats.spearmanr(y, y_pred)[0]\n",
        "    try:\n",
        "        KRCC = scipy.stats.kendalltau(y, y_pred)[0]\n",
        "    except:\n",
        "        KRCC = scipy.stats.kendalltau(y, y_pred, method='asymptotic')[0]\n",
        "\n",
        "    PLCC = scipy.stats.pearsonr(y, y_pred_logistic)[0]\n",
        "    RMSE = np.sqrt(mean_squared_error(y, y_pred_logistic))\n",
        "    return [SRCC, KRCC, PLCC, RMSE]\n",
        "\n",
        "def run_evaluation(iter_idx, X_train_full, y_train_full, X_test_full, y_test_full, is_same_dataset):\n",
        "    np.random.seed(iter_idx)\n",
        "\n",
        "    # CASE A: Same Dataset (70/10/20 Split)\n",
        "    if is_same_dataset:\n",
        "        n = len(y_train_full)\n",
        "        perm = np.random.permutation(n)\n",
        "        n_train = int(n * 0.7)\n",
        "        n_val = int(n * 0.1)\n",
        "\n",
        "        train_idx = perm[:n_train]\n",
        "        val_idx = perm[n_train:n_train+n_val]\n",
        "        test_idx = perm[n_train+n_val:]\n",
        "\n",
        "        X_tr, y_tr = X_train_full[train_idx], y_train_full[train_idx]\n",
        "        X_val, y_val = X_train_full[val_idx], y_train_full[val_idx]\n",
        "        X_te, y_te = X_train_full[test_idx], y_train_full[test_idx]\n",
        "\n",
        "    # CASE B: Cross Dataset (Train on A, Test on B)\n",
        "    else:\n",
        "        # Use 90% of Train Set for Training, 10% for Hyperparam Validation\n",
        "        n = len(y_train_full)\n",
        "        perm = np.random.permutation(n)\n",
        "        n_train = int(n * 0.9)\n",
        "\n",
        "        train_idx = perm[:n_train]\n",
        "        val_idx = perm[n_train:]\n",
        "\n",
        "        X_tr, y_tr = X_train_full[train_idx], y_train_full[train_idx]\n",
        "        X_val, y_val = X_train_full[val_idx], y_train_full[val_idx]\n",
        "        X_te, y_te = X_test_full, y_test_full # Test on full Dataset B\n",
        "\n",
        "    # Scale\n",
        "    scaler = MinMaxScaler((-1, 1))\n",
        "    X_tr = scaler.fit_transform(X_tr)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_te = scaler.transform(X_te)\n",
        "\n",
        "    # Grid Search\n",
        "    best_srcc = -1\n",
        "    best_p = {'C': 10, 'gamma': 0.1}\n",
        "\n",
        "    # Small Grid\n",
        "    for c in [1, 10, 100]:\n",
        "        for g in [0.01, 0.1, 1]:\n",
        "            m = SVR(C=c, gamma=g)\n",
        "            m.fit(X_tr, y_tr)\n",
        "            p = m.predict(X_val)\n",
        "            s = scipy.stats.spearmanr(y_val, p)[0]\n",
        "            if s > best_srcc:\n",
        "                best_srcc = s\n",
        "                best_p = {'C': c, 'gamma': g}\n",
        "\n",
        "    # Final Train\n",
        "    X_final = np.vstack((X_tr, X_val))\n",
        "    y_final = np.concatenate((y_tr, y_val))\n",
        "    final_m = SVR(C=best_p['C'], gamma=best_p['gamma'])\n",
        "    final_m.fit(X_final, y_final)\n",
        "\n",
        "    # Test\n",
        "    preds = final_m.predict(X_te)\n",
        "    return compute_metrics(preds, y_te)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Feature Combination Analysis ===\")\n",
        "\n",
        "    # 1. Inputs\n",
        "    t_name, t_mos_file, t_zip = get_dataset_info(\"SELECT TRAINING DATASET\")\n",
        "    if not t_name: exit()\n",
        "\n",
        "    test_name, test_mos_file, test_zip = get_dataset_info(\"SELECT TESTING DATASET\")\n",
        "    if not test_name: exit()\n",
        "\n",
        "    is_same = (t_name == test_name) and (t_zip == test_zip)\n",
        "    if is_same:\n",
        "        print(f\"\\n[Mode] Same Dataset Evaluation (70/10/20 on {t_name})\")\n",
        "    else:\n",
        "        print(f\"\\n[Mode] Cross Dataset Evaluation (Train {t_name} -> Test {test_name})\")\n",
        "\n",
        "    # 2. Unzip\n",
        "    train_extract_path = \"./train_feats_extracted\"\n",
        "    test_extract_path = \"./test_feats_extracted\"\n",
        "\n",
        "    unzip_features(t_zip, train_extract_path)\n",
        "    if not is_same:\n",
        "        unzip_features(test_zip, test_extract_path)\n",
        "    else:\n",
        "        test_extract_path = train_extract_path\n",
        "\n",
        "    # 3. Load MOS Dataframes\n",
        "    df_train = pd.read_excel(t_mos_file)\n",
        "    df_train.columns = [c.strip() for c in df_train.columns]\n",
        "\n",
        "    df_test = pd.read_excel(test_mos_file)\n",
        "    df_test.columns = [c.strip() for c in df_test.columns]\n",
        "\n",
        "    # Detect MOS Columns\n",
        "    def get_cols(df):\n",
        "        if 'Image' in df.columns: name = 'Image'\n",
        "        elif 'image_name' in df.columns: name = 'image_name'\n",
        "        else: name = df.columns[0]\n",
        "        return name, 'MOS'\n",
        "\n",
        "    t_name_col, t_mos_col = get_cols(df_train)\n",
        "    test_name_col, test_mos_col = get_cols(df_test)\n",
        "\n",
        "    # 4. Find Feature Subfolders (Configurations)\n",
        "    # We look in the training folder to get the list of configs (S1_FA, etc.)\n",
        "    # We handle the case where zip extracted into a subfolder\n",
        "    subfolders = [f.name for f in os.scandir(train_extract_path) if f.is_dir()]\n",
        "    if not subfolders:\n",
        "        # Check one level deeper\n",
        "        inner = [f.path for f in os.scandir(train_extract_path) if f.is_dir()]\n",
        "        if len(inner) == 1:\n",
        "            train_extract_path = inner[0]\n",
        "            subfolders = [f.name for f in os.scandir(train_extract_path) if f.is_dir()]\n",
        "\n",
        "            # Adjust test path similarly if different\n",
        "            if not is_same:\n",
        "                inner_test = [f.path for f in os.scandir(test_extract_path) if f.is_dir()]\n",
        "                if len(inner_test) == 1:\n",
        "                    test_extract_path = inner_test[0]\n",
        "\n",
        "    if not subfolders:\n",
        "        print(\"Error: No feature subfolders found in zip.\")\n",
        "        exit()\n",
        "\n",
        "    subfolders.sort()\n",
        "\n",
        "    # 5. Iterate Over Configurations\n",
        "    results_table = []\n",
        "    print(f\"\\nEvaluating {len(subfolders)} configurations...\")\n",
        "\n",
        "    for config in tqdm(subfolders, desc=\"Configurations\"):\n",
        "\n",
        "        # Paths\n",
        "        t_folder = os.path.join(train_extract_path, config)\n",
        "        test_folder = os.path.join(test_extract_path, config)\n",
        "\n",
        "        # Load Data\n",
        "        X_train, y_train = load_features_from_folder(t_folder, df_train, t_name_col, t_mos_col)\n",
        "\n",
        "        if is_same:\n",
        "            X_test, y_test = X_train, y_train\n",
        "        else:\n",
        "            # Check if test folder exists (it should if zips match)\n",
        "            if not os.path.exists(test_folder):\n",
        "                continue\n",
        "            X_test, y_test = load_features_from_folder(test_folder, df_test, test_name_col, test_mos_col)\n",
        "\n",
        "        if len(X_train) == 0 or len(X_test) == 0:\n",
        "            continue\n",
        "\n",
        "        # Impute\n",
        "        if np.isnan(X_train).any():\n",
        "            imp = SimpleImputer(strategy='mean')\n",
        "            X_train = imp.fit_transform(X_train)\n",
        "            if is_same:\n",
        "                X_test = X_train\n",
        "            else:\n",
        "                # Handle test imputation separately or use train stats\n",
        "                if np.isnan(X_test).any():\n",
        "                     X_test = imp.transform(X_test)\n",
        "\n",
        "        # Run Parallel Iterations\n",
        "        metrics = Parallel(n_jobs=N_JOBS)(delayed(run_evaluation)\n",
        "                                          (i, X_train, y_train, X_test, y_test, is_same)\n",
        "                                          for i in range(NUM_ITERATIONS))\n",
        "\n",
        "        metrics = np.array(metrics)\n",
        "        means = np.mean(metrics, axis=0)\n",
        "\n",
        "        # Add to Table\n",
        "        n_dim = X_train.shape[1]\n",
        "        results_table.append({\n",
        "            \"Configuration\": f\"{config} ({n_dim})\",\n",
        "            \"SRCC\": means[0],\n",
        "            \"KRCC\": means[1],\n",
        "            \"PLCC\": means[2],\n",
        "            \"RMSE\": means[3]\n",
        "        })\n",
        "\n",
        "    # 6. Display Results\n",
        "    if results_table:\n",
        "        res_df = pd.DataFrame(results_table)\n",
        "        res_df = res_df.sort_values(by=\"SRCC\", ascending=False)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"RESULTS TABLE ({NUM_ITERATIONS} Iterations)\")\n",
        "        print(f\"Train: {t_name} | Test: {test_name}\")\n",
        "        print(\"=\"*70)\n",
        "        print(res_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        csv_name = f\"Results_{t_name}_vs_{test_name}.csv\"\n",
        "        res_df.to_csv(csv_name, index=False)\n",
        "        print(f\"Saved to {csv_name}\")\n",
        "    else:\n",
        "        print(\"No valid results computed.\")"
      ]
    }
  ]
}